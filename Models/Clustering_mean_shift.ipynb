{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e03d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team Members: Prachitee Chouhan, Jay Singfhvi, Minh Vu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19682c37",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "# 1. Mean Shift Clustering\n",
    "\n",
    "### A. Clustering with preproprocessed data after dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f9d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import estimate_bandwidth,MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bddce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('../Data/data_preprocessed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fe86a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.07042021e+00 1.96560808e+02 2.15589512e+04 7.12207235e+00\n",
      " 4.25249290e+02 6.64654481e+01 1.42836805e+01 3.33845625e+02\n",
      " 3.96758734e+00]\n"
     ]
    }
   ],
   "source": [
    "data_cols=['ph', 'Hardness','Solids','Chloramines','Conductivity','Trihalomethanes','Organic_carbon','Sulfate','Turbidity']\n",
    "\n",
    "scaler=StandardScaler()\n",
    "data_scaled= scaler.fit_transform(data[data_cols])\n",
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a689369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantile: 0.100000\n",
      "Bandwidth: 3.010944\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.200000\n",
      "Bandwidth: 3.379553\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.300000\n",
      "Bandwidth: 3.652485\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.400000\n",
      "Bandwidth: 3.888542\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.500000\n",
      "Bandwidth: 4.112761\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.600000\n",
      "Bandwidth: 4.340260\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.700000\n",
      "Bandwidth: 4.583425\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.800000\n",
      "Bandwidth: 4.869908\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.900000\n",
      "Bandwidth: 5.265695\n",
      "Number of clusters: 1\n"
     ]
    }
   ],
   "source": [
    "for b_w in (np.arange(0.1,1,0.1)):\n",
    "    bandwidth= estimate_bandwidth(data_scaled,quantile=b_w, n_samples=500,random_state=0)\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data_scaled)  \n",
    "    labels = ms.labels_\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "    labels_unique = np.unique(labels)\n",
    "    n_clusters_ = len(labels_unique)\n",
    "    print(\"\\nQuantile: %f\"%b_w)\n",
    "    print(\"Bandwidth: %f\"%bandwidth)\n",
    "    print(\"Number of clusters: %d\"%n_clusters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e7594",
   "metadata": {},
   "source": [
    "### B. Clustering with preproprocessed data with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b0910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_outliers=pd.read_csv(\"../Data/data_preprocessed_MICE.csv\",index_col=0)\n",
    "data_with_outliers.head()\n",
    "scaler=StandardScaler()\n",
    "data_with_outliers_scaled= scaler.fit_transform(data_with_outliers[data_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4461e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantile: 0.100000\n",
      "Bandwidth: 2.935282\n",
      "Number of clusters: 10\n",
      "\n",
      "Quantile: 0.200000\n",
      "Bandwidth: 3.291729\n",
      "Number of clusters: 3\n",
      "\n",
      "Quantile: 0.300000\n",
      "Bandwidth: 3.555617\n",
      "Number of clusters: 2\n",
      "\n",
      "Quantile: 0.400000\n",
      "Bandwidth: 3.789651\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.500000\n",
      "Bandwidth: 4.014613\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.600000\n",
      "Bandwidth: 4.248310\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.700000\n",
      "Bandwidth: 4.506218\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.800000\n",
      "Bandwidth: 4.818700\n",
      "Number of clusters: 1\n",
      "\n",
      "Quantile: 0.900000\n",
      "Bandwidth: 5.259018\n",
      "Number of clusters: 1\n"
     ]
    }
   ],
   "source": [
    "for b_w in (np.arange(0.1,1,0.1)):\n",
    "    bandwidth= estimate_bandwidth(data_with_outliers_scaled,quantile=b_w, n_samples=500,random_state=0)\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data_with_outliers_scaled)  \n",
    "    labels = ms.labels_\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "    labels_unique = np.unique(labels)\n",
    "    n_clusters_ = len(labels_unique)\n",
    "    print(\"\\nQuantile: %f\"%b_w)\n",
    "    print(\"Bandwidth: %f\"%bandwidth)\n",
    "    print(\"Number of clusters: %d\"%n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6bbc4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "bandwidth = estimate_bandwidth(data_with_outliers_scaled,quantile=0.3, n_samples=500, random_state=0)\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(data_with_outliers_scaled)  \n",
    "labels = ms.labels_\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters = len(labels_unique)\n",
    "cluster_centers = ms.cluster_centers_\n",
    "print(\"Number of clusters: %d\"%n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e6f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4cde18",
   "metadata": {},
   "source": [
    "Take away:\n",
    "1. Two mean shift clustering models were prepared, one with dataset after dealing with outliers and another before \n",
    "dealing with outliers. The model with dataset after dealing with outliers was not able to correctly estimate\n",
    "the number of clusters. While, the model with later dataset, was correctly varying the number of clusters along the \n",
    "range of bandwidth (hence, quauntile). With increase in bandwidth (and quantile),number of clusters decreases. So, \n",
    "optimal quantile is 0.3 and bandwidth is 3.55"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
